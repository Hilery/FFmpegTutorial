# 0x09 使用 Core Image 渲染视频帧

本篇教程与前面三篇有区别，支持的像素格式不再是 RGB 家族，而是改用 YUV，像素格式转换逻辑修改也比较简单，增加对应的枚举值即可，这里就不再贴代码了。

## iPhone 7 plus 真机实测数据

以下数据是以 Xcode 提供的数据为标准，并且不开启 Performance 监控（MRAppDelegate 里注释掉 [PerformanceWrapper show]; ），使用 demo 里提供的带时间水印的视频测量而来。

停留在首页时记录数据为：CPU 占用 1%，内存 17.5M；

进入 0x09ViewController 之后，观察渲染情况；

USE imageWithCGImage MR_PIX_FMT_MASK_RGBA

 - 第 20s 视频： CPU 占用 9%，内存 60.7M；
 - 第 40s 视频： CPU 占用 13%，内存 60.9M；
 - 第 61s 视频： CPU 占用 3%，内存 54.3M；
 - 峰值： CPU 最高 19%， 内存最高 62.3M;
 
USE initWithBitmapData MR_PIX_FMT_MASK_RGBA
 - 第 20s 视频： CPU 占用 11%，内存 63.7M；
 - 第 40s 视频： CPU 占用 13%，内存 62.7M；
 - 第 61s 视频： CPU 占用 3%，内存 58.2M；
 - 峰值： CPU 最高 31%， 内存最高 63.7M;

USE CVPixelBuffer MR_PIX_FMT_MASK_NV12

 - 第 20s 视频： CPU 占用 8%，内存 60.6M；
 - 第 40s 视频： CPU 占用 11%，内存 61M；
 - 第 61s 视频： CPU 占用 3%，内存 56.2M；
 - 峰值： CPU 最高 23%， 内存最高 63.5M;



### 结论

从数据来看，使用 Core Image 渲染视频在 CPU 和内存使用上均比使用 Core Animation 更少一些，从 CPU 使用上来看可以用于实际项目中！