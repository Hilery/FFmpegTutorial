# 使用 GLKView 渲染视频

考虑到上一篇我们将 avframe 转成 UIImage 时，其中 CIImage 是中间产物，本篇教程的目标是使用 GLKView 渲染 CIImage，来看看他的表现如何吧。

这是我测试之后的数据:

```
缓存20s的视频包；缓存2s的解码帧;
 
 19fps GPU 10% CPU 35% Memory 70M
 
 //上篇教程的数据
 when USEBITMAP 1
 
 22fps GPU 12% CPU 55% Memory 110M
 
 when USEBITMAP 0
 
 22fps GPU 14% CPU 50% Memory 26M
```

**注：一定不要使用模拟器去查看这些参数，因为模拟器是通过 x86_64 架构的电脑模拟出来的环境和真实环境相差特别大！**

由于大部分逻辑都是基于第四天教程的，所以直接贴下核心代码:

## 核心代码

开始读包前设置下转换格式，准备下渲染 render

```
// 渲染View
if(!self.glContext){
    self.glContext = [[EAGLContext alloc] initWithAPI:kEAGLRenderingAPIOpenGLES3];
    self.ciContext = [CIContext contextWithEAGLContext:self.glContext];
    
    CGSize vSize = self.view.bounds.size;
    CGFloat vh = vSize.width * self.vheight / self.vwidth;
    CGRect rect = CGRectMake(0, (vSize.height-vh)/2, vSize.width , vh);
    self.glView = [[GLKView alloc] initWithFrame:rect context:self.glContext];
    [self.view addSubview:self.glView];
}

enum AVPixelFormat pix_fmt = PIX_FMT_NV12;
const int picSize = avpicture_get_size(pix_fmt, self.vwidth, self.vheight);
    
self.out_buffer = malloc(picSize);
self.img_convert_ctx = sws_getContext(self.vwidth, self.vheight, self.format, self.vwidth, self.vheight, pix_fmt, SWS_BICUBIC, NULL, NULL, NULL);
    
self.pFrameYUV = av_frame_alloc();
avpicture_fill((AVPicture *)self.pFrameYUV, self.out_buffer, pix_fmt, self.vwidth, self.vheight);            
```

帧格式转换方法

```
- (CIImage *)imageFromAVFrame:(AVFrame*)video_frame w:(int)w h:(int)h
{
    CVPixelBufferRef pixelBuffer = [MRConvertUtil pixelBufferFromAVFrame:video_frame w:self.vwidth h:self.vheight];
    CIImage *ciImage = nil;
    if (pixelBuffer) {
        ciImage = [CIImage imageWithCVPixelBuffer:pixelBuffer];
    }
    return ciImage;
}
```

解码线程逻辑修改

```
// 根据配置把数据转换成 NV12 或者 RGB24
int pictRet = sws_scale(self.img_convert_ctx, (const uint8_t* const*)video_frame->data, video_frame->linesize, 0, self.vheight, self.pFrameYUV->data, self.pFrameYUV->linesize);
    
if (pictRet <= 0) {
    av_frame_free(&video_frame);
    return ;
}
    
CIImage *img = [self imageFromAVFrame:self.pFrameYUV w:self.vwidth h:self.vheight];
    
// 获取时长
const double frameDuration = av_frame_get_pkt_duration(video_frame) * self.videoTimeBase;
av_frame_free(&video_frame);
// 构造模型
MRVideoFrame *frame = [[MRVideoFrame alloc]init];
frame.duration = frameDuration;
frame.ciImage = img;
```

渲染

```
CIImage *ciimage = frame.ciImage;
if (_glContext != [EAGLContext currentContext]){
    [EAGLContext setCurrentContext:_glContext];
}
[_glView bindDrawable];
CGFloat scale = [[UIScreen mainScreen]scale];
    
[_ciContext drawImage:ciimage inRect:CGRectMake(0, 0, _glView.bounds.size.width*scale, _glView.bounds.size.height*scale) fromRect:ciimage.extent];
    
[_glView display];
```

完整逻辑可打开工程查看运行。

## 分析

相比上一篇 USEBITMAP 0 时的情况，是省去了把 CIImage 转 CGImageRef，再把 CGImageRef 转成 UIImage 的过程！我觉得性能上会好些，没想到的是 fps，CPU，GPU 都降了，内存增加了近两倍！这是什么鬼？