# 播放音频

对于视频的学习初步目标已经达到了，可是到现在为止还没听到过声音，不要着急，从今天开始学习如何渲染音频。

iOS 平台用于渲染音频的技术有以下几种：

- AudioUnit
- AudioQueue
- OpenAL

本篇教程介绍如何使用 AudioUnit 渲染 FFmpeg 解码数据，其流程如下：

```
- 根据流信息，确定解码器；
- 打开文件流（avcodec_open2)
- 读包（av_read_frame） 
- 解码得到PCM（avcodec_decode_audio4）
- 使用 AudioUnit 渲染
```

AudioUnit 是 iOS 系统实时性最好的音频处理框架，也可以使用较为上层的 AudioQueue，或者 OpenAL 等，后续教程会整理相应 demo 供大家参考。

# AudioUnit

The audio unit can do input as well as output. Bus 0 is used for the output side,bus 1 is used to get audio input.
            
Apple input/output audio unit sub types (iOS)

- kAudioUnitSubType_GenericOutput
- kAudioUnitSubType_VoiceProcessingIO
- kAudioUnitSubType_RemoteIO

与视频渲染不同的是，音频不是主动送去渲染的，而是等着 AudioUnit 来要数据！要一次就给一次，需要注意的是，解出来的帧往往比要一次的要大，所以要记录下偏移量，下次从偏移量处继续给！

经过测试，AudioUnit 支持 S16P，S16，FLOAT，FLOATP 等音频格式，看 kxMovie 源码时，作者统一转成了 S16 处理，我猜测是为了简单处理吧，并不是设别不支持，这与网上有些博客写的有出入，所以做技术只能信一半，剩下一半需要自己验证！你可以通过解注释下面的语句进行验证：

```
// 测试目标输出: S16P
isFloat = false; isS16 = true; isPlanar = true;
// 测试目标输出: S16
isFloat = false; isS16 = true; isPlanar = false;
// 测试目标输出: FLOAT
isFloat = true; isS16 = false; isPlanar = false;
// 测试目标输出: FLOATP
isFloat = true; isS16 = false; isPlanar = true;
```

# 总结

最难的就是如何将获取到的 PCM 数据塞到 AudioUnit 回调 buffer 里，当初我卡了很久，因此这部分结合自己的理解加了很多注释，希望能给大家一些启发。

# 参考

- https://blog.csdn.net/gamereborn/article/details/80232453