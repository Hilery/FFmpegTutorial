# 播放音频

上一篇我们学习了如何使用 AudioUnit 渲染音频，其实已经必要学习 AudioQueue 了，因为前者更加高效，实际项目也会优先考虑 AudioUnit ，不过作为一个技术人员，我们还是要研究下的，毕竟他们是有区别的，或者说 AudioQueue 是有限制的。

本篇教程介绍如何使用 AudioQueue 渲染 FFmpeg 解码数据，其流程跟使用 AudioUnit 渲染时一样的：

```
- 根据流信息，确定解码器；
- 打开文件流（avcodec_open2)
- 读包（av_read_frame） 
- 解码得到PCM（avcodec_decode_audio4）
- 使用 AudioQueue 渲染
```

# AudioQueue

与视频渲染不同的是，音频不是主动送去渲染的，而是等着 AudioQueue 来要数据！要一次就给一次，需要注意的是，解出来的帧往往比要一次的要大，所以要记录下偏移量，下次从偏移量处继续给！

经过测试，AudioQueue 支持 S16，FLOAT 等音频格式，应该是不支持 Planar 类型，因为 AudioQueue 回调的 AudioQueueBufferRef 只有一个 inBuffer->mAudioData 这一个指针来指向数据，我还没有想到如何支持 Planar 类型，这个后续有时间了我再进一步研究下。目前你可以通过解注释下面的语句进行验证：

```
// 测试目标输出: S16
isFloat = false; isS16 = true; isPlanar = false;
// 测试目标输出: FLOAT
isFloat = true; isS16 = false; isPlanar = false;
```

# 总结

最难的仍旧是如何将获取到的 PCM 数据塞到 AudioQueue 回调 buffer 里，不过有了 AudioUnit 的经验后，这个就简单了些，结合自己的理解加了很多注释，希望能给大家一些启发。