
## 0x11 使用 Core Animation 渲染视频帧

本篇教程仅仅将  [0x10](./0x10.md) 教程使用重写 UIView drawRect 方法渲染 CGImageRef 的方式改为将 CGImageRef 转成 UIImage，然后使用 UIImageView 渲染而已，核心代码如下：

```objc
- (void)reveiveFrameToRenderer:(CGImageRef)cgImage
{
    UIImage *image = [UIImage imageWithCGImage:cgImage];

    dispatch_async(dispatch_get_main_queue(), ^{
        self.imgView.image = image;
    });
}
```

虽然看起来改动很简单，但实际上渲染方式的确变了！

## iPhone 7 plus 真机实测数据

以下数据是以 Xcode 提供的数据为标准，并且不开启 Performance 监控（MRAppDelegate 里注释掉 [PerformanceWrapper show]; ），使用 demo 里提供的带时间水印的视频，像素格式使用 MR_PIX_FMT_MASK_0RGB 测量而来。

停留在首页时记录数据为：CPU 占用 1%，内存 17.5M；

进入 0x08ViewController 之后，观察渲染情况；

 - 第 20s 视频： CPU 占用 37%，内存 30.7M；
 - 第 40s 视频： CPU 占用 37%，内存 31M；
 - 第 61s 视频： CPU 占用 3%，内存 27.1M；

整个过程的峰值：

CPU 最高 46%， 内存最高 34.2M;

从数据来看，使用 Core Animation 渲染视频在 CPU 和内存使用上均比使用 [Core Graphics](./0x10.md) 要少一些，这是什么原因呢？

## CGImage vs UIImage

WWDC 2012 Said:

- UIImage is a lightweight wrapper around CGImage
- CALayer also has CGImage as contents
- CGImage backed by file or data, eventually by bitmap
- Use UIImageView instead of drawing image directly (usually) 
  - CA can get the bitmap from the CGImage directly
  - Allow blending to happen on GPU
  - Built-in bitmap caching

CGImage 可以通过文件路径创建，可以通过原始数据（没有解码）创建 ，可以通过解码后的像素数据创建，可谓非常灵活。

UIImage 可以通过 CGImage 创建而来，当使用 UIImageView 渲染 UIImage 时，如果还没解码则会先在主线程解码，已经解过码，Core Animation 则会直接从 CGImage 获取 bitmap，并建立缓存。（顺便提下图片解码这个事，异步线程解码图片然后将解过码的 CGImage 构造成 UIImage，是众多开源图片缓存框架提升图片渲染性能的核心逻辑，这样做避免了渲染前在主线程使用 CPU 解码，导致的性能问题！）

通常情况下**应当使用 UIImageView 显示图片，而不是通过 Core Graphics 绘制**，通过对比发现这样做的确可以提高性能！

与使用  [Core Graphics](./0x10.md) 对比：

- 没有后备存储器的开销，并且有 bitmap cache

尽管 CPU 和内存使用都下降了，但是当前 CPU 的消耗还是挺大的，需要继续寻找更优的渲染方式，下一篇我们将使用 [Core Image](./0x12.md) 渲染试试。

另外换成 MR_PIX_FMT_MASK_RGB555 格式后内存变化很小，但是 CPU 使用却明显上升了，这跟 Core Graphics  的表现不一样，我猜测可能是 UIImageView 内部使用 CPU 对像素格式做了转换以及字节对齐等因素导致的，可自行测试。
