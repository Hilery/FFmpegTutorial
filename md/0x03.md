## 核心代码


本教程是在 0x02 的基础上修改的，主要增加了循环读包和 AVPacket 缓存队列。

### 循环读包

正常情况下，包是需要一直读的，除非关闭了播放器，因此写了个死循环，必要的时候 break 出来：



```objective-c
AVPacket pkt1, *pkt = &pkt1;
    ///循环读包
    for (;;) {
        
        ///调用了stop方法，线程被标记为取消了，则不再读包
        if ([[NSThread currentThread] isCancelled]) {
            break;
        }
        
        ///
        if (self.abort_request) {
            break;
        }
        
        /* 队列不满继续读，满了则休眠 */
        if (audioq.size + videoq.size > MAX_QUEUE_SIZE
            || (stream_has_enough_packets(audio_st, audio_stream, &audioq) &&
                stream_has_enough_packets(video_st, video_stream, &videoq))) {
            /* wait 10 ms */
            usleep(10000);
            continue;
        }
        
        ///读包
        int ret = av_read_frame(formatCtx, pkt);
        ///读包出错
        if (ret < 0) {
            //读到最后结束了
            if ((ret == AVERROR_EOF || avio_feof(formatCtx->pb)) && !eof) {
                ///最后放一个空包进去
                if (video_stream >= 0) {
                    packet_queue_put_nullpacket(&videoq, video_stream);
                }
                    
                if (audio_stream >= 0) {
                    packet_queue_put_nullpacket(&audioq, audio_stream);
                }
                //标志为读包结束
                eof = 1;
            }
            
            if (formatCtx->pb && formatCtx->pb->error) {
                break;
            }
            
//            SDL_LockMutex(wait_mutex);
//            SDL_CondWaitTimeout(is->continue_read_thread, wait_mutex, 10);
//            SDL_UnlockMutex(wait_mutex);
            usleep(10000);
            continue;
        } else {
            //音频包入音频队列
            if (pkt->stream_index == audio_stream) {
                audioq.serial ++;
                packet_queue_put(&audioq, pkt);
            }
            //视频包入视频队列
            else if (pkt->stream_index == video_stream) {
                videoq.serial ++;
                packet_queue_put(&videoq, pkt);
            }
            //其他包释放内存忽略掉
            else {
                av_packet_unref(pkt);
            }
        }
    }
```



这里的配置沿用 FFPlay 的参数，所以每个缓存队列的大小是 25 帧，总大小不超过 15MB。

### AVPacket 缓存队列

下面是通过链表实现队列的逻辑：

```objective-c
///packet 链表
typedef struct MyAVPacketList {
    AVPacket pkt;
    struct MyAVPacketList *next;
    int serial;
} MyAVPacketList;

///packet 队列
typedef struct PacketQueue {
    ///头尾指针
    MyAVPacketList *first_pkt, *last_pkt;
    //队列里包含了多少个包
    int nb_packets;
    //所有包暂用的内存大小
    int size;
    //所有包总的时长，注意单位不是s
    int64_t duration;
    //最后一个包的序号
    int serial;
    //锁
    dispatch_semaphore_t mutex;
//    SDL_mutex *mutex;
//    SDL_cond *cond;
} PacketQueue;

///packet 队列初始化
static __inline__ int packet_queue_init(PacketQueue *q)
{
    memset((void*)q, 0, sizeof(PacketQueue));
    q->mutex = dispatch_semaphore_create(1);
//    q->cond = SDL_CreateCond();
//    if (!q->cond) {
//        av_log(NULL, AV_LOG_FATAL, "SDL_CreateCond(): %s\n", SDL_GetError());
//        return AVERROR(ENOMEM);
//    }
    return 0;
}

///向队列追加入一个packet(非线程安全操作)
static int packet_queue_put_private(PacketQueue *q, AVPacket *pkt)
{
    MyAVPacketList *pkt1;
    //创建链表节点
    pkt1 = av_malloc(sizeof(MyAVPacketList));
    if (!pkt1)
        return -1;
    pkt1->pkt = *pkt;
    pkt1->next = NULL;
    pkt1->serial = q->serial;

    ///队尾是空的，则说明队列为空，作为队首即可
    if (!q->last_pkt){
        q->first_pkt = pkt1;
    }
    ///队尾不空，则把这个节点和当前队列的最后一个节点连接
    else {
        q->last_pkt->next = pkt1;
    }
    ///更新尾结点为当前
    q->last_pkt = pkt1;
    //更新相关信息
    q->nb_packets++;
    q->size += pkt1->pkt.size + sizeof(*pkt1);
    q->duration += pkt1->pkt.duration;
    /* XXX: should duplicate packet data in DV case */
//    SDL_CondSignal(q->cond);
    return 0;
}

///向队列加入一个packet(线程安全的操作)
static int packet_queue_put(PacketQueue *q, AVPacket *pkt)
{
    int ret;
    ///获取信号量
    dispatch_semaphore_wait(q->mutex, DISPATCH_TIME_FOREVER);
    ret = packet_queue_put_private(q, pkt);
    dispatch_semaphore_signal(q->mutex);

    if (ret < 0)
        av_packet_unref(pkt);

    return ret;
}

///向队列加入一个空packet(线程安全的操作)
static int packet_queue_put_nullpacket(PacketQueue *q, int stream_index)
{
    AVPacket pkt1, *pkt = &pkt1;
    av_init_packet(pkt);
    pkt->data = NULL;
    pkt->size = 0;
    pkt->stream_index = stream_index;
    return packet_queue_put(q, pkt);
}

///缓存队列是否满
static int stream_has_enough_packets(AVStream *st, int stream_id, PacketQueue *queue) {
    return stream_id < 0 ||
           (st->disposition & AV_DISPOSITION_ATTACHED_PIC) ||
    (queue->nb_packets > MIN_FRAMES && (!queue->duration || av_q2d(st->time_base) * queue->duration > 1.0));
}
```



## 总结

为了尽可能高效的利用 CPU 资源，解封装读包、音频解码、视频解码均在各自的线程中完成，再加上 1 个AVPacket 和 2 个 AVFrame 的音视频缓存队列，共三个线程，三个缓存区。

这篇教程主要实现了解封装读包线程和 AVPacket 缓存队列，其中 AVPacket 缓存队列的实现大部分摘抄自 FFPlay 的源码，这块实现挺好的，所以没必要再写一遍，而是直接拿来了。线程同步改为了 iOS 支持的 semaphore，从跨平台的角度讲，不应使用 NSThread 及使用信号量实现锁，但是为了照顾广大 iOS 开发者，暂时不用 pthread 实现，从而降低学习的门槛。