
## 0x04 多线程解码

在  [0x03](./0x03.md) 教程中，我们实现了循环读包和 AVPacket 缓存队列，这里相当于有了生产者，这篇教程就来实现解码，相当于是个消费者，在 [播放器总体架构设计](./illiteracy/0x02.md) 篇中我们了解到播放器解码数据是以 AVFrame 为载体的，本篇教程的目标是拿到 AVFrame，并且只关注音频和视频的解码。

## 解码线程思路分析

正常情况下，需要持续解码，除非关闭了播放器或者AVPacket 缓存队列为空或者已经解码了足够的 AVFrame。每次解码前需要检查上述的三个条件：

- 满足一个，则等待片刻继续检查；
- 均不满足，则获取一个 AVPacket，进行解码

音视频包的解码时间是抖动的，有的时候发现解码某一帧视频需要的时间可能会长一些，为了不相互影响，并且充分利用多核CPU资源，决定为音频和视频分配独立的解码线程。

### 线程生命周期

1、创建线程，在解码器打卡后创建线程

```objc
//根据流类型，准备相关线程
    switch (avctx->codec_type) {
        case AVMEDIA_TYPE_AUDIO:
        {
            audio_stream = idx;
            audio_st = stream;
            audioCodecCtx = avctx;
            [self prepareAudioDecodeThread];
        }
            break;
        case AVMEDIA_TYPE_VIDEO:
        {
            video_stream = stream->index;
            video_st = stream;
            videoCodecCtx = avctx;
            [self prepareVideoDecodeThread];
        }
            break;
        default:
            break;
    }

- (void)prepareAudioDecodeThread
{
    ///避免NSThread和self相互持有，外部释放self时，NSThread延长self的生命周期，带来副作用！
    MRRWeakProxy *weakProxy = [MRRWeakProxy weakProxyWithTarget:self];
    ///不允许重复准备
    self.audioDecodeThread = [[NSThread alloc] initWithTarget:weakProxy selector:@selector(audioDecodeFunc) object:nil];
}

- (void)prepareVideoDecodeThread
{
    ///避免NSThread和self相互持有，外部释放self时，NSThread延长self的生命周期，带来副作用！
    MRRWeakProxy *weakProxy = [MRRWeakProxy weakProxyWithTarget:self];
    ///不允许重复准备
    self.videoDecodeThread = [[NSThread alloc] initWithTarget:weakProxy selector:@selector(videoDecodeFunc) object:nil];
}
```

2、启动线程，在读包循环开始之前启动解码线程

```objc
//开始解码线程
[self.audioDecodeThread start];
[self.videoDecodeThread start];

//循环读包
[self readPacketLoop:formatCtx];
```

3、销毁线程，调用 _stop 的时候


```objc
[self.audioDecodeThread cancel];
self.audioDecodeThread = nil;

[self.videoDecodeThread cancel];
self.videoDecodeThread = nil;
```

## 解码流程

1、每个流的都有个索引，类型为int，因此使用长度为 AVMEDIA_TYPE_NB 的 int 数组存放结果

```objc
//确定最优的音视频流
int st_index[AVMEDIA_TYPE_NB];
memset(st_index, -1, sizeof(st_index));
[self findBestStreams:formatCtx result:&st_index];
```

2、查找最优的音视频流

```objc
- (void)findBestStreams:(AVFormatContext *)formatCtx result:(int (*) [AVMEDIA_TYPE_NB])st_index {

    int first_video_stream = -1;
    int first_h264_stream = -1;
    //查找H264格式的视频流
    for (int i = 0; i < formatCtx->nb_streams; i++) {
        AVStream *st = formatCtx->streams[i];
        enum AVMediaType type = st->codecpar->codec_type;
        st->discard = AVDISCARD_ALL;

        if (type == AVMEDIA_TYPE_VIDEO) {
            enum AVCodecID codec_id = st->codecpar->codec_id;
            if (codec_id == AV_CODEC_ID_H264) {
                if (first_h264_stream < 0) {
                    first_h264_stream = i;
                    break;
                }
                if (first_video_stream < 0) {
                    first_video_stream = i;
                }
            }
        }
    }
    //h264优先
    (*st_index)[AVMEDIA_TYPE_VIDEO] = first_h264_stream != -1 ? first_h264_stream : first_video_stream;
    //根据上一步确定的视频流查找最优的视频流
    (*st_index)[AVMEDIA_TYPE_VIDEO] = av_find_best_stream(formatCtx, AVMEDIA_TYPE_VIDEO, (*st_index)[AVMEDIA_TYPE_VIDEO], -1, NULL, 0);
    //参照视频流查找最优的音频流
    (*st_index)[AVMEDIA_TYPE_AUDIO] = av_find_best_stream(formatCtx, AVMEDIA_TYPE_AUDIO, (*st_index)[AVMEDIA_TYPE_AUDIO], (*st_index)[AVMEDIA_TYPE_VIDEO], NULL, 0);
}

```

这里使用了数组指针，在 C 语言里，数值指针这么声明：`int (*st_index)[AVMEDIA_TYPE_NB]`，这里是 OC 方法，因此遵循 OC 方法的格式书写就变成了 `(int (*) [AVMEDIA_TYPE_NB])st_index`。使用 `(*st_index)[i]` 获取第 i 个数组元素，这个括号是必须要带的！

3、打开解码器，创建解码线程

```objc
- (int)openStreamComponent:(AVFormatContext *)ic streamIdx:(int)idx
{
    if (ic == NULL) {
        return -1;
    }
    
    if (idx < 0 || idx >= ic->nb_streams){
        return -1;
    }
    
    AVStream *stream = ic->streams[idx];
    
    //创建解码器上下文
    AVCodecContext *avctx = avcodec_alloc_context3(NULL);
    if (!avctx) {
        return AVERROR(ENOMEM);
    }
    
    //填充下相关参数
    if (avcodec_parameters_to_context(avctx, stream->codecpar)) {
        avcodec_free_context(&avctx);
        return -1;
    }
    
    av_codec_set_pkt_timebase(avctx, stream->time_base);
    
    //查找解码器
    AVCodec *codec = avcodec_find_decoder(avctx->codec_id);
    if (!codec){
        avcodec_free_context(&avctx);
        return -1;
    }
    
    avctx->codec_id = codec->id;
    
    //打开解码器
    if (avcodec_open2(avctx, codec, NULL)) {
        avcodec_free_context(&avctx);
        return -1;
    }
    
    stream->discard = AVDISCARD_DEFAULT;
    
    //根据流类型，准备相关线程
    switch (avctx->codec_type) {
        case AVMEDIA_TYPE_AUDIO:
        {
            audio_stream = idx;
            audio_st = stream;
            audioCodecCtx = avctx;
            //创建音频解码线程
            [self prepareAudioDecodeThread];
        }
            break;
        case AVMEDIA_TYPE_VIDEO:
        {
            video_stream = stream->index;
            video_st = stream;
            videoCodecCtx = avctx;
            //创建视频解码线程
            [self prepareVideoDecodeThread];
        }
            break;
        default:
            break;
    }
    return 0;
}
```

4、音视频通用解码方法

```objc
- (int)decoder_decode_frame:(AVCodecContext *)avctx queue:(PacketQueue *)queue frame:(AVFrame*)frame {
    
    for (;;) {
        int ret;
        do {
            //停止时，直接返回
            if (self.abort_request){
                return -1;
            }
            
            //先尝试接收帧
            ret = avcodec_receive_frame(avctx, frame);
            
            //成功接收到一个解码帧
            if (ret >= 0){
                return 1;
            }
            
            //结束标志，此次并没有获取到frame！
            if (ret == AVERROR_EOF) {
                avcodec_flush_buffers(avctx);
                return AVERROR_EOF;
            }
            
        } while (ret != AVERROR(EAGAIN)/*需要更多packet数据*/);
        
        AVPacket pkt;
        //[阻塞等待]直到获取一个packet
        int r = packet_queue_get(queue, &pkt, 1);
       
        if (r < 0)
        {
            return -1;
        }
        
        //发送给解码器去解码
        if (avcodec_send_packet(avctx, &pkt) == AVERROR(EAGAIN)) {
            av_log(avctx, AV_LOG_ERROR, "Receive_frame and send_packet both returned EAGAIN, which is an API violation.\n");
        }
        //释放内存
        av_packet_unref(&pkt);
    }
}
```

5、音频解码线程

```objc
- (void)audioDecodeFunc
{
    if ([[NSThread currentThread] isCancelled]) {
       return;
    }
       
    @autoreleasepool {
        [[NSThread currentThread] setName:@"audio_decode"];
        
        //创建一个frame就行了，可以复用
        AVFrame *frame = av_frame_alloc();
        if (!frame) {
            av_log(NULL, AV_LOG_ERROR, "can't alloc a frame.");
            return;
        }
        do {
            //使用通用方法解码音频队列
            int got_frame = [self decoder_decode_frame:audioCodecCtx queue:&audioq frame:frame];
            //解码出错
            if (got_frame < 0) {
                if (got_frame == AVERROR_EOF) {
                    av_log(NULL, AV_LOG_ERROR, "decode frame eof.");
                } else if (self.abort_request){
                    av_log(NULL, AV_LOG_ERROR, "cancel decoder.");
                } else {
                    av_log(NULL, AV_LOG_ERROR, "can't decode frame.");
                }
                break;
            } else {
                //正常解码
                av_log(NULL, AV_LOG_VERBOSE, "decode a audio frame:%lld\n",frame->pts);
                sleep(1);
            }
        } while (1);
        
        //释放内存
        if (frame) {
            av_frame_free(&frame);
        }
        
        //释放解码器上下文
        if (audioCodecCtx) {
            avcodec_free_context(&audioCodecCtx);
            audioCodecCtx = NULL;
        }
    }
}
```

6、视频解码线程

```objc
- (void)videoDecodeFunc
{
    if ([[NSThread currentThread] isCancelled]) {
       return;
    }
       
    @autoreleasepool {
        [[NSThread currentThread] setName:@"video_decode"];
        
        //创建一个frame就行了，可以复用
        AVFrame *frame = av_frame_alloc();
        if (!frame) {
            av_log(NULL, AV_LOG_ERROR, "can't alloc a frame.\n");
            return;
        }
        do {
            //使用通用方法解码音频队列
            int got_frame = [self decoder_decode_frame:videoCodecCtx queue:&videoq frame:frame];
            //解码出错
            if (got_frame < 0) {
                if (got_frame == AVERROR_EOF) {
                    av_log(NULL, AV_LOG_ERROR, "decode frame eof.\n");
                } else if (self.abort_request){
                    av_log(NULL, AV_LOG_ERROR, "cancel decoder.");
                } else {
                    av_log(NULL, AV_LOG_ERROR, "can't decode frame.");
                }
                break;
            } else {
                //正常解码
                av_log(NULL, AV_LOG_VERBOSE, "decode a video frame:%lld\n",frame->pts);
                
                sleep(2);
            }
        } while (1);
        
        //释放内存
        if (frame) {
            av_frame_free(&frame);
        }
        
        //释放解码器上下文
        if (videoCodecCtx) {
            avcodec_free_context(&videoCodecCtx);
            videoCodecCtx = NULL;
        }
    }
}
```



## 总结

这篇教程主要实现了使用独立线程解码音视频流，**解码逻辑是对 IJKPlayer 源码的精简**，这也是使用 FFmpeg 编写解码的通用流程！下一篇为大家介绍如何缓存解码后的 AVFrame 。

